---
title: "CSP 571 Course Project"
author: "Basketball Salaries Team"
output: pdf_document
geometry: margin=1cm
---

# Load, Clean, and Link Data

## Load NBA 2K Data
Note: Primary dataset is directly downloaded from Kaggle. This video-game rankings dataset is scraped from http://mtdb.com/20
```{r message=F}
library(stringr)
library(rvest)
library(tidyr)
if (!file.exists('data/raw/nba2k/nba2k_16.csv')){ # only run if data is not already scraped
# constants
root <- 'data/raw/nba2k'
years <- c(16,17,18,19,20)
pages = c(84,68,72,68,46)
url_f <- 'http://mtdb.com/%d?page=%d&sortedBy=overall&sortOrder=Descending&'
for (i in 1:length(years)){
  year_df <- vector('list',12)
  names(year_df) <- c('name','position','ovr','out','ins','pla','ath','def','reb','xbox','ps4','pc')
  year <- years[i]
  page <- pages[i]
  for (page in 1:page){
    # load webpage 
    url <- sprintf(url_f,year,page)
    webpage <- read_html(url)
    # load salary table
    player_tables <- html_nodes(webpage, css = 'table')
    player_df_page <- html_table(player_tables[[1]])#[-(1),]
    names(player_df_page) <- c('name','position','ovr','out','ins','pla','ath','def','reb','xbox','ps4','pc')
    year_df <- rbind(year_df,player_df_page)}
  write.csv(year_df,sprintf('%s/nba2k_%d.csv',root,year))
  cat(sprintf('%d nrows: %d\n',year,nrow(year_df)))}}
```

## Clean Primary Dataset
```{r message=F}
library("readxl")
df_primary <- read_excel('data/raw/primary_dataset_raw.xlsx')
df_primary <- df_primary[,!(names(df_primary)%in%c('#','blanl','blank2'))] # drop empty/non-stat columns
colnames(df_primary)[1:3] <- c('year','name_p','salary')
df_primary <- df_primary[!is.na(df_primary[['salary']]),] # drop rows with no salaryes
df_primary[is.na(df_primary)] <- 0
df_primary <- df_primary[df_primary$year%in%c(2016:2020),]   # take 2016-2017 player data
head(df_primary)
summary(df_primary)
```

## Pool Together and Clean NBA 2K Data (Secondary Dataset)
```{r}
secondary_attriutes <- c('name_s','position_s','ovr','out','ins','pla','ath','def','reb')
df_secondary <- vector('list',9)
names(df_secondary) <- secondary_attriutes
path_f = 'data/raw/nba2k/nba2k_%d.csv'
for (year in c(16:20)){
  df_year <- read.csv(sprintf(path_f,year))
  headers <- names(df_year)
  names(df_year) <- c('drop1',headers[1:length(headers)-1])
  df_year <- df_year[,c('name','position','ovr','out','ins','pla','ath','def','reb')]
  names(df_year) <- secondary_attriutes
  df_year[,'year'] <- 2000+year
  df_secondary <- rbind(df_secondary,df_year)}
df_secondary[is.na(df_secondary)] <- 0
df_secondary <- df_secondary[df_secondary$year%in%c(2016,2017),]   # take 2016-2017 2K ratings data
head(df_secondary)
summary(df_secondary)
```

## Merge Primary and Secondary Datasets
```{r}
library(stringr)
clean_names <- function(names){
  names <- tolower(names)
  names <- str_squish(names)
  names <- gsub('\\.','',names)
  names <- gsub('-',' ',names)
  return (names)}
df_primary$name <- clean_names(df_primary[['name_p']])
df_secondary$name <- clean_names(df_secondary[['name_s']])
# if multiple versions of a player, take the one with the max overall
df_secondary_max <- aggregate(df_secondary['ovr'],df_secondary[c('name','year')],max)
df_secondary_max <- merge(df_secondary_max,df_secondary,by=c('name','year','ovr'),all=F)
df_secondary_max_2 <- aggregate(df_secondary_max['out'],df_secondary_max[c('name','year')],max)
df_full_s <- merge(df_secondary_max,df_secondary_max_2,by=c('name','year','out'),all=F)
# only take totals from players who changed teams mid-year
df_p_tot <- df_primary[df_primary$Tm=='TOT',]
traded_player_years <- interaction(df_primary[,c('year','name')]) %in% 
                       interaction(df_p_tot[,c('year','name')])
df_p_wo_tot <- df_primary[!traded_player_years,]
df_full_p <- rbind(df_p_wo_tot,df_p_tot)
# join datasets
df_full <- merge(df_full_p,df_full_s,by=c('name','year'),all=F)
df_full <- df_full[order(df_full$name,df_full$year),]
df_full <- unique(df_full)
head(df_full[,1:5])

```

## Clean Up Merged Data and 
```{r}
drop_cols <- c('name','name_s','position_s')
df_final <- df_full[,!(names(df_full)%in%drop_cols)]
names(df_final)[names(df_final)=='position_p'] <- 'position'
names(df_final)[names(df_final)=='name_p'] <- 'name'
s_columns <- c('ovr','out','ins','pla','ath','def','reb')
df_p_final <- df_final[,!(names(df_final)%in%s_columns)] # final primary dataset
df_s_final <- df_final[,c('name',s_columns)] # final secondary dataset
head(df_final) # final complete (combined primary and secondary) datasets
summary(df_final)
# Output final complete, primary, and seconday datasets
write.csv(df_final,'data/pooled/complete.csv')
write.csv(df_p_final,'data/pooled/primary.csv')
write.csv(df_s_final,'data/pooled/secondary.csv')
```

# Explore Data

## Summarize Datasets
```{r}
# primary dataset
str(df_p_final)
# secondary dataset
str(df_s_final)
```

## Complete Dataset Histograms
```{r eval=F}
library(purrr)
library(tidyr)
library(ggplot2)
df_final %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) + 
      facet_wrap(~ key, scales = "free") + 
      geom_histogram(aes(y=..density..), fill = "grey") + 
      geom_density()
ggsave("figures/hist_complete_vars.png", width=15, height=13)
```

## Bar Chart of Player by Team from Complete Dataset
```{r}
library(ggplot2)
ggplot(df_final, aes(x = Tm)) + 
  geom_bar(fill = "grey") + 
  labs(x = "Team", title = "Players per team") +
  theme(axis.text.x=element_text(angle=45,hjust=1,vjust=0.5))
ggsave("figures/bar_complete_player_per_team.png", width=10, height=7)
```

## Sum of Salaries per Team for Complete Dataset
```{r message=F}
library(ggplot2)
library(tidyr)
library(dplyr)
df_final %>%
  group_by(Tm) %>%
  summarise(sum_salary = sum(salary)) %>%
  ggplot(aes(x = Tm, y = sum_salary, fill = Tm)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Team",
        y = "Sum of salaries",
        title = paste("Sum of salaries per team")) + 
    theme(axis.text.x=element_text(angle=45,hjust=1,vjust=0.5))
ggsave("figures/bar_complete_sum_salaries_per_team.png", width=10, height=7)
```

## Mean Salaries per Team for Complete Dataset
```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
df_final %>%
  group_by(Tm) %>%
  summarise(mean_salary = mean(salary)) %>%
  ggplot(aes(x = Tm, y = mean_salary, fill = Tm)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Team",
        y = "mean salary",
        title = paste(
            "mean salary per team")) + 
    theme(axis.text.x=element_text(angle=45,hjust=1,vjust=0.5))
ggsave("figures/bar_complete_mean_salaries_per_team.png", width=10, height=7)
```

## Players in each position
```{r}
library(ggplot2)
ggplot(df_final, aes(x = Pos)) + 
  geom_bar(fill = "orange") + 
  labs(x = "Position", title = "No of Player for each position") +
  theme_classic()
ggsave("figures/bar_complete_player_Position.png", width=10, height=7)
```

## Mean salaries for each position
```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
df_final %>%
  group_by(Pos) %>%
  summarise(mean_salary = mean(salary)) %>%
  ggplot(aes(x = Pos, y = mean_salary, fill = Pos)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Pos",
        y = "mean salary",
        title = paste(
            "mean salary for Position")) 
ggsave("figures/bar_complete_mean_salaries_for_Position.png", width=10, height=7)
```

## Correlation Matrix for complete dataset
```{r}
corr_matrix_c <- cor(Filter(is.numeric,df_final[2:ncol(df_final)]),method = "pearson")
correlation_salary_c <- sort(corr_matrix_c[,'salary'],decreasing = TRUE)
correlation_salary_c
```

## Correlation Plot for complete dataset
```{r}
library(corrplot)
corrplot(corr_matrix_c,type = "upper")
```

## Correlation plot for Primary dataset
```{r}
corr_matrix_p <- cor(Filter(is.numeric,df_p_final[2:ncol(df_p_final)]),method = "pearson")
correlation_salary_p <- sort(corr_matrix_p[,'salary'],decreasing = TRUE)
correlation_salary_p
```

```{r}
library(corrplot)
corrplot(corr_matrix_p,type = "upper")
```

## Save correlation plots.
```{r}
# complete dataset
png(file = "figures/Correlation_plot_c.png")
corrplot(corr_matrix_c,type = "upper")
# primary dataset
png(file = "figures/Correlation_plot_p.png")
corrplot(corr_matrix_p,type = "upper")
dev.off()
```

## Detecting outliers
```{r}
plot = function(variable)
{
  print(variable)
  ggplot(df_final,aes(x = df_final[,variable], y = salary)) + geom_point() + theme_classic() + labs(x=variable)
}


library(gridExtra)
p = list()
p <- NULL
val <- 0
d <- df_final[,4:ncol(df_final)]
for(j in 1:5)
{
  for(i in 1:11) {
  name = names(d[i+val])
  p[[i]] = plot(as.character(name))
  }
  val = i+val
do.call(grid.arrange,p)
p <- NULL
}
```

# VARIABLE SELECTION

## Helper Functions
```{r}
get_salary_formula <- function(x_vars){
  return(as.formula(sprintf('salary ~ `%s`',paste(x_vars,collapse='` + `'))))}
```

## Primary Dataset Variable Selection Using Automated F-Test-Based Backward Selection
```{r}
library(rms)
p_x_vars <- names(df_p_final)[!(names(df_p_final))%in%c('salary','name','2P','TRB','2PA','PTS')]
# 2P, 2PA, PTS, and TRB were causing singularity in predictor matrix, so they were dropped
p_formula <- get_salary_formula(p_x_vars)
p_formula
p_selection_model <- ols(p_formula, data = df_p_final)
p_selection_model
p_seleced <- fastbw(p_selection_model, rule = "p", sls = 0.1)
p_seleced

```

## Checking for Multicollinearity Among Optimal Subset of Primary Variables.
```{r}
p_subset_formula <- get_salary_formula(p_seleced[['names.kept']])
p_subset_formula
p_subset_lm <- lm(p_subset_formula , data=df_p_final)
summary(p_subset_lm)
vif(p_subset_lm) # All variables have low VIF values. So no multicollinearity.
p_vars_final <- p_seleced[['names.kept']]
```

## Complete Dataset Variable Selection Using Automated F-Test-Based Backward Selection
```{r}
library(rms)
c_x_vars <- names(df_final)[!(names(df_final)%in%c('salary','name','2P','2PA','PTS','TRB'))]
# 2P, 2PA, PTS, and TRB were causing singularity in predictor matrix, so they were dropped
c_formula <- get_salary_formula(c_x_vars)
c_formula
c_selection_model <- ols(c_formula, data = df_final)
c_selection_model
c_seleced <- fastbw(c_selection_model, rule = "p", sls = 0.1)
c_seleced
```

## Checking for Multicollinearity Among Optimal Subset of Complete Variables.
```{r}
c_subset_formula <- get_salary_formula(c_seleced[['names.kept']])
c_subset_formula
c_subset_lm <- lm(c_subset_formula , data=df_final)
summary(c_subset_lm)
vif(c_subset_lm) # All variables have low VIF values. So no multicollinearity.
c_vars_final <- c_seleced[['names.kept']]
```

## Subset Primary and Complete Dataframes to Include Only Name, Salary, and Selected Variables
```{r}
p_vars_subset <- c('name','salary',p_vars_final)
df_p_subset_final <- df_p_final[,p_vars_subset]
c_vars_subset <- c('name','salary',c_vars_final)
df_c_subset_final <- df_final[,c_vars_subset]
```

# Split Train-Test

```{r message=F}
library(caret)
set.seed(7)
```

## Primary Dataset
```{r}

train_rows <- createDataPartition(y=df_p_subset_final[,'salary'], list=FALSE, p=.8)
p_train_df <- df_p_subset_final[train_rows,]
p_test_df <- df_p_subset_final[-train_rows,]
stopifnot(nrow(p_train_df) + nrow(p_test_df) == nrow(df_p_subset_final))
nrow(p_train_df)
nrow(p_test_df)
names(p_train_df)
head(p_train_df)
write.csv(p_train_df,'data/train_test/primary/train.csv')
write.csv(p_test_df,'data/train_test/primary/test.csv')
```

## Complete Dataset
```{r}
library(caret)
set.seed(7)
train_rows <- createDataPartition(y=df_c_subset_final[,'salary'], list=FALSE, p=.8)
c_train_df <- df_c_subset_final[train_rows,]
c_test_df <- df_c_subset_final[-train_rows,]
stopifnot(nrow(c_train_df) + nrow(c_test_df) == nrow(df_c_subset_final))
nrow(c_train_df)
nrow(c_test_df)
names(c_train_df)
head(c_train_df)
write.csv(c_train_df,'data/train_test/complete/train.csv')
write.csv(c_test_df,'data/train_test/complete/test.csv')
```








