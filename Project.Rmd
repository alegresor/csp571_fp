---
title: "CSP 571 Course Project"
author: "Basketball Salaries Team"
output: pdf_document
geometry: margin=1cm
---

## DATA CLEANING

## Clean Primary dataset
```{r message=F}
library("readxl")
df_primary <- read_excel('data/raw/primary_dataset_raw.xlsx')
df_primary <- df_primary[,!(names(df_primary)%in%c('#','blanl','blank2'))] # drop empty/non-stat columns
colnames(df_primary)[1:3] <- c('year','name_p','salary')
df_primary <- df_primary[!is.na(df_primary[['salary']]),] # drop rows with no salaryes
df_primary[is.na(df_primary)] <- 0
df_primary <- df_primary[df_primary$year%in%c(2016:2020),]   # take 2016-2017 player data
head(df_primary)
summary(df_primary)
```

## Pool 2k Data
## Pull nba 2k ratings 

```{r}
secondary_attriutes <- c('name_s','position_s','ovr','out','ins','pla','ath','def','reb')
df_secondary <- vector('list',9)
names(df_secondary) <- secondary_attriutes
path_f = 'data/raw/nba2k/nba2k_%d.csv'
for (year in c(16:20)){
  df_year <- read.csv(sprintf(path_f,year))
  headers <- names(df_year)
  names(df_year) <- c('drop1',headers[1:length(headers)-1])
  df_year <- df_year[,c('name','position','ovr','out','ins','pla','ath','def','reb')]
  names(df_year) <- secondary_attriutes
  df_year[,'year'] <- 2000+year
  df_secondary <- rbind(df_secondary,df_year)}
df_secondary[is.na(df_secondary)] <- 0
df_secondary <- df_secondary[df_secondary$year%in%c(2016,2017),]   # take 2016-2017 2K ratings data
head(df_secondary)
names(df_secondary)
```

## Link datasets

```{r}
library(stringr)
clean_names <- function(names){
  names <- tolower(names)
  names <- str_squish(names)
  names <- gsub('\\.','',names)
  names <- gsub('-',' ',names)
  return (names)}
df_primary$name <- clean_names(df_primary[['name_p']])
df_secondary$name <- clean_names(df_secondary[['name_s']])
# if multiple versions of a player, take the one with the max overall
df_secondary_max <- aggregate(df_secondary['ovr'],df_secondary[c('name','year')],max)
df_secondary_max <- merge(df_secondary_max,df_secondary,by=c('name','year','ovr'),all=F)
df_secondary_max_2 <- aggregate(df_secondary_max['out'],df_secondary_max[c('name','year')],max)
df_full_s <- merge(df_secondary_max,df_secondary_max_2,by=c('name','year','out'),all=F)
# only take totals from players who changed teams mid-year
df_p_tot <- df_primary[df_primary$Tm=='TOT',]
traded_player_years <- interaction(df_primary[,c('year','name')]) %in% 
                       interaction(df_p_tot[,c('year','name')])
df_p_wo_tot <- df_primary[!traded_player_years,]
df_full_p <- rbind(df_p_wo_tot,df_p_tot)
# join datasets
df_full <- merge(df_full_p,df_full_s,by=c('name','year'),all=F)
df_full <- df_full[order(df_full$name,df_full$year),]
df_full <- unique(df_full)
head(df_full[,1:5])

```


## Final minor cleanups
```{r}
drop_cols <- c('name','name_s','position_s')
df_final <- df_full[,!(names(df_full)%in%drop_cols)]
names(df_final)[names(df_final)=='position_p'] <- 'position'
names(df_final)[names(df_final)=='name_p'] <- 'name'
s_columns <- c('ovr','out','ins','pla','ath','def','reb')
df_p_final <- df_final[,!(names(df_final)%in%s_columns)]
df_s_final <- df_final[,c('name',s_columns)]
head(df_final)
head(df_p_final)
head(df_s_final)
summary(df_final)
summary(df_p_final)
summary(df_s_final)

```

## Output to files
```{r}
write.csv(df_final,'data/pooled/complete.csv')
write.csv(df_p_final,'data/pooled/primary.csv')
write.csv(df_s_final,'data/pooled/secondary.csv')
```


## DATA EXPLORATION

```{r}
df_final <- read.csv('data/pooled/complete.csv')

df_s_final <- read.csv('data/pooled/secondary.csv')

df_p_final <- read.csv('data/pooled/primary.csv')
summary(df_p_final)
str(df_p_final)
summary(df_s_final)
str(df_s_final)
```

## Primary data
```{r}
library(purrr)
library(tidyr)
library(ggplot2)
df_p_final[4:ncol(df_p_final)] %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value))+ facet_wrap(~ key, scales = "free") + geom_histogram(aes(y=..density..), fill = "grey") + geom_density()
 
```

```{r}
ggplot(df_final, aes(x = Tm)) + geom_bar(fill = "grey") + labs(x = "Team", title = "Players per team")
```

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
df_final %>%
  group_by(Tm) %>%
  summarise(sum_salary = sum(salary)) %>%
  ggplot(aes(x = Tm, y = sum_salary, fill = Tm)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Team",
        y = "Sum of salaries",
        title = paste(
            "Sum of salaries per team"
        )
    )
```

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
df_final %>%
  group_by(Tm) %>%
  summarise(mean_salary = mean(salary)) %>%
  ggplot(aes(x = Tm, y = mean_salary, fill = Tm)) +
    geom_bar(stat = "identity") +
    theme_classic() +
    labs(
        x = "Team",
        y = "mean salary",
        title = paste(
            "mean salary per team"
        )
    )
```
## Secondary data
```{r}
library(ggplot2)
library(tidyr)
df_s_final[3:ncol(df_s_final)] %>%
  keep(is.numeric) %>% 
  gather() %>% 
    ggplot(aes(value)) + facet_wrap(~ key, scales = "free") + geom_histogram(aes(y=..density..), fill = "grey") + geom_density()

```


## VARIABLE SELECTION

## PRIMARY DATASET

## Dividing into training and test data
```{r}
set.seed(34543)
sample <- sample(df_p_final$X, size = 0.8 * nrow(df_p_final), replace = FALSE)
train <- df_p_final[df_p_final$X %in% sample, ]
test <- df_p_final[!df_p_final$X %in% sample, ]
# Always check key assumptions like below!!!
stopifnot(nrow(train) + nrow(test) == nrow(df_p_final))
nrow(train)
nrow(test)
nrow(df_p_final)
```


## Correlation plot for primary dataset
```{r}
par(mar=c(1,1,1,1))
library(corrplot)
d <- train[which(sapply(train, is.numeric))]
corr_matrix <- cor(d,method = "pearson")
cplot <- corrplot(corr_matrix)
```

## correlation between all variables and salary
```{r}
correlation_salary <- sort(corr_matrix[2:nrow(corr_matrix),'salary'],decreasing = TRUE)
correlation_salary
str(correlation_salary)
```

## Using Automated F-test-based backward selection

```{r}
library(rms)
Varselection <- ols(salary ~ WS + PTS+FG+FTA+FGA+OWS+`X2P`+`X2PA`+VORP+MP+DWS+GS+TOV+DRB+PER+TRB+BPM+OBPM+AST+STL+`WS.48`+USG.+PF+BLK+G+AST.+TS.+FTr+eFG.+FG.+ Age+DBPM+`X2P.`+DRB.+FT.+TRB.+`X3P.`+BLK.+STL.+ORB.+TOV.+`X3PAr`, data = df_p_final)
fastbw(Varselection, rule = "p", sls = 0.1)
```

## Checking for multicollinearity among variables.
```{r}
variables <- lm(salary ~ FG + OWS + MP + DWS + STL + G + Age , data = df_p_final)
summary(variables)
vif(variables) # All variables have low VIF values. So no multicollinearity.
```



## COMPLATE DATASET

```{r}
set.seed(34543)
sample <- sample(df_final$X, size = 0.8 * nrow(df_final), replace = FALSE)
train <- df_final[df_final$X %in% sample, ]
test <- df_final[!df_final$X %in% sample, ]
# Always check key assumptions like below!!!
stopifnot(nrow(train) + nrow(test) == nrow(df_final))
nrow(train)
nrow(test)
nrow(df_final)
```


## Correlation plot for primary dataset
```{r}
par(mar=c(1,1,1,1))
library(corrplot)
d <- train[which(sapply(train, is.numeric))]
corr_matrix <- cor(d,method = "pearson")
cplot <- corrplot(corr_matrix)
```

## correlation between all variables and salary
```{r}
correlation_salary <- sort(corr_matrix[2:nrow(corr_matrix),'salary'],decreasing = TRUE)
correlation_salary
str(correlation_salary)
```

## Using Automated F-test-based backward selection

```{r}
library(rms)
Varselection <- ols(salary ~ WS + PTS+FG+FTA+FGA+OWS+`X2P`+`X2PA`+VORP+MP+DWS+GS+TOV+DRB+PER+TRB+BPM+OBPM+AST+STL+`WS.48`+USG.+PF+BLK+G+AST.+TS.+FTr+eFG.+FG.+ Age+DBPM+`X2P.`+DRB.+FT.+TRB.+`X3P.`+BLK.+STL.+ORB.+TOV.+`X3PAr`+ovr+def+ins+ath+out+pla+reb, data = df_final)
fastbw(Varselection, rule = "p", sls = 0.1)
```

## Checking for multicollinearity among variables.

```{r}
variables <- lm(salary ~  OWS + MP + DWS + STL +USG.+ G + Age + ovr  , data = df_final)
summary(variables)
vif(variables) # All variables have low VIF values. So no multicollinearity.
```








